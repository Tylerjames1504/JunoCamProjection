{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projecting JunoCam images\n",
    "Raw *JunoCam* images consist of several framelets, each corresponding to a different filter. As the spacecraft moves, the framelets correspond to different parts of the sky. To project the raw image to a map, we need to calculate the positions of each pixel in the image. \n",
    "\n",
    "Also be sure to compile the C script in the `projection/` folder. To do this, open the `projection/` folder in a terminal, and run `make`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once those are done, import the projector functions. The first command points to the location of the `JunoCamProjection` module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/rsankar/JunoCamProjection/')\n",
    "from projection import projector\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The projection functions make use of the [SPICE toolkit](https://naif.jpl.nasa.gov/naif/toolkit.html) which read in kernel files that are produced by NAIF. These kernel files define the position of planets and spacecraft and are updated periodically. \n",
    "\n",
    "To project *JunoCam* data, we will need the Juno kernels. You can get these by using the `wget` command. Open a terminal, `cd` to the folder where you want the kernls to be, and enter the following command:\n",
    "```bash\n",
    "wget -m -nH --cut-dirs=3 -nv ftp://naif.jpl.nasa.gov/pub/naif/JUNO/kernels/\n",
    "```\n",
    "\n",
    "This will create a `kernels/` folder and populate it with different kernels that define the *Juno* spacecraft and Jupiter. In the next cell, set `KERNEL_DATAFOLDER` to point to the `kernels` folder that was created. \n",
    "\n",
    "**WARNING: The downloaded data is in excess of 30 GBs. Make sure you have the disk space for it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "KERNEL_DATAFOLDER = '/home/rsankar/kernels/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now initialize the `Projector` class with the location of our image and metadata that's associated with it. *JunoCam* images can be downloaded from [the JunoCam Processing website](https://www.missionjuno.swri.edu/junocam/processing). To process the raw images, be sure to select the JUNOCAM filter so as to filter out user generated images. \n",
    "\n",
    "Click on the image, and download the images and metadata zips to this folder. Unzip them to produce the`ImageSet/` and `DataSet/` folders. Note the name of metadata file inside the `Dataset/` folder. \n",
    "\n",
    "We initialize the Projector class by inputting the folder containing the images (`ImageSet/`), the metadata file (`DataSet/xxxx-Metadata.json`) and the location of the kernels. This example shows the included GRS image from Perijove 27 (ID: 8724). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = projector.Projector(\"ImageSet/\", \"DataSet/8724-Metadata.json\", KERNEL_DATAFOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the object is initialized, we can project it. Call the `process` method, which can run in parallel with the `num_procs` argument. This call calculates the lat/lon of the center of each pixel in the original JunoCam framelet, correcting for barrel distortions (see Optical Distortions section [here](https://naif.jpl.nasa.gov/pub/naif/JUNO/kernels/ik/juno_junocam_v03.ti)) and for interframe delay. The code also automatically determines the best value for the jitter in the image start time by fitting the limb of the planet (see timing note [here](https://naif.jpl.nasa.gov/pub/naif/JUNO/kernels/ik/juno_junocam_v03.ti)). \n",
    "\n",
    "Note: This will take some time (5-10 mins), so you can go grab something to drink. Also, **be sure to change the number of processors as needed**.  \n",
    "\n",
    "In the end, the code will produce a netCDF4 file which contains the location of each pixel, the time/location of the spacecraft for each framelet and a illumination-geometry corrected image. The name of this file is given by the `FILE_NAME` attribute in the metadata file which can be accessed via `proj.fname`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JNCE_2020154_27C00047_V01\n",
      "Projecting framelets:\n",
      "Found best jitter value of -23.0 ms\n",
      "[=================== ] 97.44%\n",
      "Extents - lon: -84.087 105.134 lat: -80.006 1.832 - lowest pixres: 0.020 deg/pix\n"
     ]
    }
   ],
   "source": [
    "proj.process(num_procs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now, we will need to combine the framelets so that we can get a 'map-projected' image. Ideally this should be in one of the [standard cartographic projections](https://en.wikipedia.org/wiki/List_of_map_projections#pseudocylindrical) but, for now, we'll just use a lon/lat grid.\n",
    "\n",
    "To project the map, we need to define our grid. The `proj` object defined above calculates the extent of the image. These can be determined from the object attributes (`lonmin`, `lonmax`, `latmin`, `latmax`) and we can create a uniform spacing between them. \n",
    "\n",
    "Once these are created, we call the `map_project` function and use the input the newly generated netCDF4 file. This code can be parallelized with the `num_procs` option as before, and use `save=True` if you want to save the RGB frames to a PNG file and the mosaic to a netCDF4 file (`filename`_proj.nc where `filename` is the `proj.fname` attribute as before). \n",
    "\n",
    "We can provide extents for the final map, or let the code automatically determine the bounds of the mosaic. If you want to let the code determine this automatically, you must provide a pixel resolution using the `pixres` argument (units of degrees/pixel). \n",
    "\n",
    "If you want pass in specific bounds, define the arrays for the latitude and longitude extents:\n",
    "```python\n",
    "latg = np.arange(-10, 10, 1./25.) # latitude range -10 to +10 at 25 pixels per degree\n",
    "long = np.arange(-30, 30, 1./25.) # longitude range -30 to +30 at 25 pixels per degree\n",
    "datafile, IMG, mask = projector.map_project(\"%s.nc\"%proj.fname, latg=latg, long=long, ...)\n",
    "```\n",
    "\n",
    "This step will also take a few minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projecting JNCE_2020154_27C00047_V01\n",
      "Using raw IMG\n",
      "Limits: lon: -84.087 90.713  lat: -80.006 1.794  size: 4371 x 2046\n",
      " 2000/2046 Processing B\n",
      " 19/20\n",
      "[=================== ] 97.20%\n",
      "Processing G\n",
      " 19/20\n",
      "[==================  ] 94.39%\n",
      "Processing R\n",
      " 19/20\n",
      "[=================== ] 97.17%\n",
      "Processing emission angles\n",
      " 19/20\n",
      "[=================== ] 97.23%\n",
      "Processing incidence angles\n",
      " 19/20\n",
      "[=====               ] 25.26%"
     ]
    }
   ],
   "source": [
    "resolution=25 ## pixels/degree\n",
    "datafile, IMG, mask = projector.map_project(f\"{proj.fname}.nc\", pixres=1./resolution, save=True, num_procs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.imshow(IMG/np.percentile(IMG.flatten(), 99), origin='lower')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns the name of netCDF file where the projected data is stored, the projected RGB image and the image mask (which shows which pixels in the mosaic contain data). By default the code performs a simple Lambertian lighting correction to remove image gradients, but this is usually not enough to smoothen out the lighting. You can turn this correction using `scorr_method='None'`. \n",
    "\n",
    "We can perform other corrections on the image. One of the more robust ones is to use FFT high pass filter, which removes low frequency (large scale) brightness variations. The `fft_radius` defines the filter threshold, in pixels. I find that 5-10 is a good threshold to capture small details but remove large scale variations. Since we defined `save=True` above, we can just load in the projected image (using `load=True`), and rerun the code with the new correction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution=25 ## pixels/degree\n",
    "datafile, IMG, mask = projector.map_project(f\"{proj.fname}.nc\", pixres=1./resolution, save=True, num_procs=10,\n",
    "                                           scorr_method='fft', fft_radius=8, load=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.imshow(IMG/IMG.max(), origin='lower')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we do a basic color correction, normalization and gamma correction to the image. You can save out the new image to a PNG file (with filename given by the `fname` argument) with `save=True`. This will create a `[fname]_mosaic_RGB.png` in the `mos/` folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_corr = projector.color_correction(f\"nc/{datafile}\", gamma=1.1, hist_eq=True, clip_limit=0.008, \n",
    "                                      fname=proj.fname, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot this in an orthographic projection (i.e. similar to what the spacecraft might have seen). The `sat_height_scale` defines how high above the surface your viewpoint is. Lower values bring you closer, but increases the 'fish-eye' effect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projector.plot_ortho(f\"nc/{datafile}\", sat_height_scale=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
